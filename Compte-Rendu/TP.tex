\documentclass{article}
\usepackage[french]{babel}
\usepackage[latin1]{inputenc}
\usepackage{array}
\usepackage{amsmath, amssymb}
\usepackage{tikz}
\usetikzlibrary{calc, shapes, backgrounds}
\usetikzlibrary{positioning,chains,fit}
\usetikzlibrary{arrows}
\usepackage{mathrsfs}
\usepackage{float}
\usepackage{pgfplots}
\usepackage{enumerate}
\usepackage{caption}
\usepackage[ruled,vlined,french,onelanguage]{algorithm2e}
\title{TP Méthode approchées UMIN215}
\author{Bruno Y., Chlöé T., Julien D. et Rémi F.}

\begin{document}
\maketitle

\section{Partie Théorique}

\subsection{Programmation linéaire en nombres entiers}
\subsubsection*{Exercice 1 - Sur le problème de la couverture sommet minimale : trois approches différentes}

\begin{enumerate}
\item
\begin{enumerate}[a)]
\item On a :
\begin{displaymath}
x_{i} = \begin{cases} 
0 \text{ si } x_{i} \notin S \\
1 \text{ si } x_{i} \in S
\end{cases}
\end{displaymath}

On peut donc déduire que le $(PL)$ donne bien une solution optimale. $z$ compte bien le nombre de sommets dans $S$. Si $(v_{r},v_{s}) \in E$, on a $x_{r}$ et $x_{s}$ qui valent $1$ : il faut qu'il y ait au moins un sommet couvre l'arête.

\item On ne peut pas avoir $x_{s} + x_{r} = 1 $ car $v_{r}$ et $v_{s}$ peuvent tout deux appartenir à S.

\item Soit une solution optimale, alors elle respecte les contraintes du $(PL)$ et correspond à un $z$ minimum: elle correspond donc à une solution du $(PL)$.

\item Supposons qu'il existe $(v_{r},v_{s})\in E$ tel que $x_{r} < \frac{1}{2}$ et $x_{s} < \frac{1}{2}$, alors on aurait $x_{r} + x_{s} < 1$, ce qui viole une contrainte. Donc $x_{r} \geq \frac{1}{2}$ ou $x_{s} \geq \frac{1}{2}$.

\item Soit $I$ une instance quelconque, alors on a $\rho = \frac{max(A(I))}{Opt(I)}$. Par ailleurs, on sait que :
\begin{equation}
 Opt(I) = S_{ILP}(I) 
\end{equation}
\begin{equation}
 S_{LP}(I) \leq S_{ILP}(I)
\end{equation}

On peut déduire de $(2)$ que $\frac{1}{S_{LP}(I)} \geq \frac{1}{S_{ILP}(I)}$. Donc on arrive à l'inéquation suivante : $\frac{A(I)}{S_{LP}(I)} \geq \frac{A(I)}{Opt(I)}$. Notons que $A(I)$ est la solution obtenue en arrondissant la solution de $S_{LP}(I)$. \\
On peut remarquer que puisqu'il existe $i$ tel que $x_{i} \geq \frac{1}{2} $, donc $2x_{i} \geq 1 $. On peut donc écrire : 

\begin{equation}
A(I) = \sum_{i, x_{i} \geq \frac{1}{2}} 1 \leq \sum_{i \in S^{*}} 2x_{i} \leq 2 \sum_{i=1}^{n} x_{i} = 2 Opt(I).
\end{equation}

On déduit finalement que $\frac{A(I)}{Opt(I)} = 2 $ et $\rho = \frac{max(A(I))}{Opt(I)} \leq 2 $
Montrons que $\rho = 2$ en considérons le cas suivant : 

\begin{figure}[H]
\center
\begin{tikzpicture}[-,>=stealth',shorten >=1pt,auto,node distance=3cm,
  thick,main node/.style={circle,fill=blue!20,draw,font=\sffamily\Large\bfseries}]

  \node[main node] (1) { $\frac{1}{2} $};
  \node[main node] (2) [below left of=1] {  $\frac{1}{2} $};
  \node[main node] (3) [below right of=2] {  $\frac{1}{2} $};
  \node[main node] (4) [below right of=1] {  $\frac{1}{2} $};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge [bend right] node[left] { }(2)
    (2) edge [bend right] node[left] { }(3)
    (3) edge [bend right] node[right] { }(4)
    (4)edge [bend right] node[right] { } (1);
\end{tikzpicture}
\caption{Résultat donné par l'Algorithme 1 pour le problème Vertex cover.}
\end{figure}

On peut remarquer qu'ici, $A(I) = 4 $ alors que $Opt(I) = 2 $.

\begin{figure}[H]
\center
\begin{tikzpicture}[-,>=stealth',shorten >=1pt,auto,node distance=3cm,
  thick,main node/.style={circle,fill=blue!20,draw,font=\sffamily\Large\bfseries}]

  \node[main node] (1) { 1 };
  \node[main node] (2) [below left of=1] { 0};
  \node[main node] (3) [below right of=2] {  1};
  \node[main node] (4) [below right of=1] {  0};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge [bend right] node[left] { }(2)
    (2) edge [bend right] node[left] { }(3)
    (3) edge [bend right] node[right] { }(4)
    (4)edge [bend right] node[right] { } (1);
\end{tikzpicture}
\caption{Résultat optimal pour le problème Vertex cover.}
\end{figure}

On peut donc finalement conclure que $\rho = \frac{max(A(I))}{Opt{I}} = 2 $.

\item 

\begin{enumerate}[i)]
\item Pour obtenir notre nouvel programme linéaire $(PL')$, il suffit simplement d'introduire les poids $w_{i} \in \mathbf{N}^{*}, i\in \{1, \dots , n \} $ et de poser $z = \sum_{j=1}^{n} w_{i} x_{i}$.

\begin{displaymath}
PL'\begin{cases} 
\text{min } z = \sum_{j=1}^{n} w_{i} x_{i} \\
x_{r} + x_{s} \geq 1, \forall \{v_{r},v_{s} \} \in E  \\
x_{j} \in \{0,1\}, j \in \{1, \dots, n \}
\end{cases}
\end{displaymath}


\item On peut remplacer le programme linéaire en nombre entiers $(PL')$ par un autre utilisant une matrice $A$. Pour un graphe $G=(V,E)$, la matrice $A$ utilisé dans le programme linéaire en nombres entiers possède les caractéristiques suivantes : 
\begin{itemize}
\item $A$ à $2*|E|$ lignes et $|V|$ colonnes.
\item Chaque ligne apparaît deux fois dans la matrice.
\item La matrice $A$ est constituée uniquement de $1$ et il n'y a que deux $1$ par ligne.
\end{itemize}

\begin{displaymath}
PL'\begin{cases} 
\text{min } z = \sum_{j=1}^{n} w_{i} x_{i} \\
A *  \left( \begin{array}{c}
x_1 \\
\vdots \\
x_n
\end{array} \right) \geq  \left( \begin{array}{c}
1 \\
\vdots \\
1
\end{array} \right). \\

x_{j} \in \{0,1\}, j \in \{1, \dots, n \}
\end{cases}
\end{displaymath}

\item A terminer..
\end{enumerate}
\end{enumerate}

\item \begin{enumerate}[a)]
\item Dans les pires des cas, les deux sommets de chaque arêtes sont pris : $A(I) \geq 2*m$ avec $m = |E|$. De plus, il y a toujours, au moins un sommet par arête dans la solution optimale : $Opt(I) \geq n $. On peut donc écrire que $\frac{1}{Opt(I)} \leq n$ et donc que $\frac{A(I)}{Opt(I)} \leq 2 $.

\item Considérons le graphe suivant :

\begin{figure}[H]
\center
\begin{tikzpicture}[-,>=stealth',shorten >=1pt,auto,node distance=3cm,
  thick,main node/.style={circle,fill=blue!20,draw,font=\sffamily\Large\bfseries}]

  \node[main node] (1) { a };
  \node[main node] (2) [below left of=1] { b};
  \node[main node] (3) [below right of=2] {  c};
  \node[main node] (4) [below right of=1] {  d};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge [bend right] node[left] { }(2)
    (2) edge [bend right] node[left] { }(3)
    (3) edge [bend right] node[right] { }(4)
    (4)edge [bend right] node[right] { } (1);
\end{tikzpicture}
\caption{Exemple d'instance pour lequel l'Algorithme 2 atteint la borne de deux.}
\end{figure}

On a donc $E' = ( \{a,b\}, \{a,d\}, \{b,c\}, \{c,d\} )$. 

\begin{figure}[H]
\center
\begin{tabular}{|c|c|c|c|}
\hline
\text{étape} & E' & \text{arête sélectionné} & C \\
\hline
1 & \{ \{a,b\}, \{a,d\}, \{b,c\}, \{c,d\} \} & \{a,b\} & \{ \{a,b\} \}\\
\hline
2 & \{ \{c,d\} \} & \{c,d\} & \{ \{a,b\}, \{c,d\} \}\\
\hline
3 & $\emptyset$ & $\emptyset$ & \{ \{a,b\}, \{c,d\} \} \\
\hline
\end{tabular}
\end{figure}

On à ici $A(I) = 4$ alors que $Opt(I) = 2 $ donc $\rho = \frac{max(A(I))}{Opt(I)} = 2 $.

\item On commence par prendre les $\frac{k!}{k}$ sommets de degrés $k$ (les triangles), puis les $\frac{k!}{k-1}$ sommets de degrés $k-1$, etc.. On va donc prendre en tout $k! \sum_{i=0}^{k} \frac{1}{k-i} = k! \sum_{i=1}^{k} \frac{1}{i} = k! * H_{k}$, avec $H_{k}$ la k-ième somme partielle de la série harmonique. L'optimal est de prendre que les $k!$ sommets de degrés $k$ (les carrés). On a donc pour un $k$ fixé, $\frac{A(I)}{Opt(I)} = H_{k}$. Or si $k \rightarrow \infty$, $H_{k}$ diverge et tend vers $\infty$.
\end{enumerate}

\end{enumerate}
\subsubsection*{Exercice 2 - Sur le problème du couplage maximum de poids maximum : un début d'étude polyédrale sur le problème de couplage}

Dans cet exercice, nous travaillerons sur un graphe $G=(V,E)$ avec $|V| = n$ et $|E|= m$. Chaque arête $(i,j) \in E$ possède un poids que l'on not $w_{i,j}$.

\begin{enumerate}
\item On peut considérer le $(PL)$ suivant afin de modéliser le problème :

\begin{displaymath}
PL\begin{cases} 
\text{max } z = \sum_{(i,j) \in E} w_{i,j} x_{i,j} \\
\forall i \in \{1,\dots,n\}, \sum_{j \in V(i)} x_{i,j} \leq 1\\
x_{j} \in \{0,1\}
\end{cases}
\end{displaymath}

\item Considérons que le graphe de la figure 2 est le suivant :

\begin{figure}[H]
\center
\begin{tikzpicture}[-,>=stealth',shorten >=1pt,auto,node distance=3cm,
  thick,main node/.style={circle,fill=blue!20,draw,font=\sffamily\Large\bfseries}]

  \node[main node] (1) { a };
  \node[main node] (2) [below left of=1] { b};
  \node[main node] (3) [below right of=1] {  c};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge [right] node[left] {1}(2)
    (2) edge [right] node[below] {1}(3)
    (3)edge [right] node[right] {1} (1);
\end{tikzpicture}
\caption{Graphe représentant la figure 2.}
\end{figure}

Les équations des contraintes sont donc les suivantes :
\begin{displaymath}
\begin{cases} 
x_{a,b} + x_{a,c} \leq 1 \\
x_{a,c} + x_{b,c} \leq 1 \\
x_{a,b} + x_{b,c} \leq 1
\end{cases}
\end{displaymath}

\item Une solution optimale du programme linéaire en nombre entiers est $z=1$ avec $x_{a,b}=1$, $x_{b,c}=0$ et $x_{a,c}=0$.

\item Une solution pour le même programme relaxé est $z=\frac{3}{2}$ avec $x_{a,b}=\frac{1}{2} $, $x_{b,c}=\frac{1}{2}$ et $x_{a,c}=\frac{1}{2}$.

\item La formulation est mauvaise puisqu'avec une solution de $LP$, on ne peut pas retrouver une solution de $ILP$.

\item Pour la figure 2, $\frac{|S| - 1}{2} = 1$. On rajoute donc la contrainte suivante : $\sum_{(i,j) \in E } x_{i,j} \leq 1 $. On remarque qu'avec cette contrainte, $z(ILP) = z(LP) = \frac{1}{3} + \frac{1}{3} + \frac{1}{3} = 1 $. Cette solution ne peut être le résultat du PL car ce n'est pas un point extrême, puisqu'il est combinaison linéaire des solutions $(1,0,0), (0,1,0)$ et $(0,0,1)$.

\item 
\begin{enumerate}[a)]
\item Pour la première figure, les solutions admissibles sont $x_{e} = x_{f} = 1$; $x_{e} = 1$ et $x_{f} = 0$ ; $x_{e} = 0$ et $x_{f} = 1$ ; $x_{e} = x_{f} = 0$ 

\pgfplotsset{vasymptote/.style={
    before end axis/.append code={
        \draw[-] ({rel axis cs:0,0} -| {axis cs:#1,0})
        -- ({rel axis cs:0,1} -| {axis cs:#1,0});
    }
}}
\begin{tikzpicture}[>=stealth]
    \begin{axis}[
        xmin=0,xmax=2,
        ymin=0,ymax=2,
        axis x line=middle,
        axis y line=middle,
        axis line style=->,
        xlabel={$x_{e}$},
        ylabel={$x_{f}$},
        vasymptote=1,
        ]
        \addplot[no marks,black,-] expression[domain=0:2,samples=100]{1} 
                    node[pos=0.65,anchor=south west]{};                     
    \end{axis}
\end{tikzpicture} \\
Le polytope associé est défini par les points $(0,0)$, $(0,1)$, $(1,0)$ et $(1,1).$ \\

Pour la deuxième figure, les différentes combinaisons possibles sont : $x_{e}=0, x_{f}=0, x_{g}=0$ ;  $x_{e}=0, x_{f}=0, x_{g}=1$; $x_{e}=0, x_{f}=1, x_{g}=0$; $x_{e}=1, x_{f}=1, x_{g}=0$ et $x_{e}=1, x_{f}=0, x_{g}=0$. Le polytope associé est une pyramide définie par une base carré ( $(0,0,0)$, $(0,1,0)$, $(1,0,0)$ et $(1,1,0).$) et un sommet ($(0,0,1)$).\\

Le cas du triangle les combinaisons possibles sont : $x_{e}=0, x_{f}=0, x_{g}=0$ ; $x_{e}=0, x_{f}=0, x_{g}=1$ ; $x_{e}=0, x_{f}=1, x_{g}=0$ et $x_{e}=1, x_{f}=0, x_{g}=0$. Le polytope associé est une pyramide définie par une base triangulaire ( $(0,0,0)$, $(0,1,0)$ et $(1,0,0)$) et un sommet ($(0,0,1)$).

\item Si $\lambda_{1} M_{1} + \lambda_{2} M_{2} + \lambda_{3} M_{3} = (\frac{1}{2}, \frac{1}{2}, \frac{1}{2})$ \\
$\lambda_{1} (1,0,0) + \lambda_{2} (0,1,0) + \lambda_{3} (0,0,1)= (\frac{1}{2}, \frac{1}{2}, \frac{1}{2})$ \\
alors $\lambda_{1} = \lambda_{2} = \lambda_{3} = \frac{1}{2}$ et donc $\sum_{i=1}^{3} \lambda_{i} = \frac{3}{2} > 1$. Le point n'appartient donc pas au polytope.

\item Soit un point $x$ du polytope fractionnaire $FM$, alors $\exists \lambda_{1}, \dots , \lambda{m}, \exists M_{1}, \dots M_{m}$ tel que $\sum_{i=1}^{m} \lambda_{i} = 1$ et $\sum_{i=1}^{m} \lambda_{i} M_{i} = x$.\\
Un graphe biparti n'est composé que de cycles pairs. Soit une solution optimale de LP.

\definecolor{myblue}{RGB}{80,80,160}
\definecolor{mygreen}{RGB}{80,160,80}

\begin{tikzpicture}[thick,
  every node/.style={draw,circle},
  fsnode/.style={fill=myblue},
  ssnode/.style={fill=mygreen},
  every fit/.style={ellipse,draw,inner sep=-2pt,text width=2cm},
  -,shorten >= 3pt,shorten <= 3pt
]

% the vertices of U
\begin{scope}[start chain=going below,node distance=7mm]
\foreach \i in {1,2,...,5}
  \node[fsnode,on chain] (f\i) [label=left: $u_{\i}$] {};
\end{scope}

% the vertices of V
\begin{scope}[xshift=4cm,yshift=-0.5cm,start chain=going below,node distance=7mm]
\foreach \i in {1,2,...,5}
  \node[ssnode,on chain] (s\i) [label=right: $v_{\i}$] {};
\end{scope}

% the set U
\node [myblue,fit=(f1) (f5),label=above:$U$] {};
% the set V
\node [mygreen,fit=(s1) (s5),label=above:$V$] {};

% the edges
\draw (f1) -- (s2);
\draw (f1) -- (s3);
\draw (f2) -- (s2);
\draw (f2) -- (s3);
\end{tikzpicture}

Considérons le cycle $(u_{1}, v_{2}, u_{2}, v_{3}, u_{1})$. \\
On a forcément $x_{u_{1},v_{2}} + x_{u_{2},v_{3}} = x_{u_{1},v_{3}} + x_{u_{2},v_{2}}$ puisque l'on prend une arête sur deux le long du cycle. Donc on peut prendre $x'_{u_{1},v_{2}} = x_{u_{1},v_{2}} + x_{u_{1},v_{3}}$, $x'_{u_{2},v_{3}}= x_{u_{2},v_{3}} + x_{u_{2},v_{2}}$ et $x'_{u_{2},v_{2}} = x'_{u_{1},v_{3}} = 0 $. \\
On répétant cette opération, on "casse" tous les cycles tout en gardant la même valeur pour la fonction objectif.
\end{enumerate}
\end{enumerate}

\subsection{Problèmes appartenant à la classe APX}
\subsubsection*{Exercice 3 - Sur le problème de la coupe maximum}

Dans cet exercice, nous travaillerons avec un graphe $G=(V,E)$ avec $|V|=n$ et $|E|=m$.
\begin{enumerate}
\item La boucle $while$ ne peut s'effectuer plus de $n$ fois puisqu'à chaque tour de boucle, nous déplaçons un sommet de l'autre côté de la coupe. Puis pour trouver un sommet qui augmente la valeur de la coupe, on parcours potentiellement tout les sommet $O(n)$ puis l'on doit calculer le nombre d'arcs dans la coupe et hors de la coupe $O(n^{2})$. On obtient en tout du $O(n^{3}).$

\item Soit $(Y_{1},Y_{2})$ la coupe rendue par l'algorithme. Montrons par l'absurde que $\forall v \in Y_{1}, |Voisins(v) \cap Y_{1} | \leq |Voisins(v) \cap Y_{2} |$. Supposons qu'il existe un sommet $v \in Y_{1}, |Voisins(v) \cap Y_{1} | > |Voisins(v) \cap Y_{2} |$, alors on pourrait déplacer ce sommet de l'autre côté de la coupe et augmenter la valeur de celle-ci de $ |Voisins(v) \cap Y_{1} | - |Voisins(v) \cap Y_{2} | > 0$. Ce qui contredit le fait que $(Y_{1},Y_{2})$ soit le résultat de l'algorithme. \\

Il nous reste à montrer que l'Algorithme est 2-approché. Posons $C$ la coupe optimale et $(Y_{1},Y_{2})$ la coupe rendue par l'algorithme. On peut donc écrire que : 

\begin{align*}
|C| &= | \{ \text{Arêtes de} Y_{1} \text{ dans }Y{1} \in C\} | + | \{ \text{Arêtes de} Y_{1} \text{ dans }Y{2} \in C\} | + | \{ \text{Arêtes de} Y_{2} \text{ dans }Y{2} \in C\} | \\
  &\leq ...
\end{align*}

\item Considérons le graphe suivant :

\begin{figure}[h]
\center
\begin{tikzpicture}[-,>=stealth',shorten >=1pt,auto,node distance=1cm,
  thick,main node/.style={circle,fill=blue!20,draw,font=\sffamily\bfseries}]

  \node[main node] (1) {a};
  \node[main node] (2) [right of=1] {b};
  \node[main node] (3) [right of=2] {c};
  \node[main node] (4) [right of=3] {d};
  \node[main node] (5) [below of=1] {e};
    \node[main node] (6) [right of=5] {f};
      \node[main node] (7) [right of=6] {g};
        \node[main node] (8) [right of=7] {h};
          \node[main node] (9) [below of=5] {i};
            \node[main node] (10) [right of=9] {j};
              \node[main node] (11) [right of=10] {k};
                \node[main node] (12) [right of=11] {l};
                  \node[main node] (13) [below of=9] {m};
                    \node[main node] (14) [right of=13] {n};
                      \node[main node] (15) [right of=14] {o};
                        \node[main node] (16) [right of=15] {p};
                        
  \path[every node/.style={font=\sffamily\small}]
    (1) edge node [right] {} (2)
    edge node [right] {} (5)
    (2) edge node [right] {} (3)
    edge node [right] {} (6)
    (3) edge node [right] {} (4)
 	edge node [right] {} (7)
    (4) edge node [right] {} (8)
    (5) edge node [right] {} (6)
    	edge node [right] {} (9)
	(6) edge node [right] {} (7)
	edge node [right] {} (10)
	(7) edge node [right] {} (8)
	edge node [right] {} (11)
	(8) edge node [right] {} (12)
	(9)edge node [right] {} (10)
	edge node [right] {} (13)
	(10) edge node [right] {} (11)
	edge node [right] {} (14)
	(11) edge node [right] {} (12)
	edge node [right] {} (15)
	(12) edge node [right] {} (16)
	(13) edge node [right] {} (14)
	(14) edge node [right] {} (15)
	(15) edge node [right] {} (16);
\end{tikzpicture}
\caption {Exemple pour lequel l'algorithme atteint sa borne.}
\end{figure}

Déroulement de l'algorithme :

\begin{figure}[H]
\center
\begin{tabular}{|c|c|c|c|}
\hline
\text{étape} & S & V - S & \text{Taille de la coupe (S, V-S)} \\
\hline
1 & $\emptyset$ & \{a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p\} & 0 \\
\hline
2 & \{a \} & \{b,c,d,e,f,g,h,i,j,k,l,m,n,o,p\} & 2 \\
\hline
3 & \{a, b \} & \{c,d,e,f,g,h,i,j,k,l,m,n,o,p\} & 3 \\
\hline
4 & \{a,b,c \} & \{d,e,f,g,h,i,j,k,l,m,n,o,p\} & 4 \\
\hline
5 & \{a,b,c,e \} & \{d,f,g,h,i,j,k,l,m,n,o,p\} & 5 \\
\hline
6 & \{a,b,c,e,i \} & \{d,f,g,h,j,k,l,m,n,o,p\} & 6 \\
\hline
7 & \{a,b,c,e,i,p \} & \{d,f,g,h,j,k,l,m,n,o\} & 8 \\
\hline
8 & \{a,b,c,e,i,p,l \} & \{d,f,g,h,j,k,m,n,o\} & 9 \\
\hline
9 & \{a,b,c,e,i,p,l,h \} & \{d,f,g,j,k,m,n,o\} & 10 \\
\hline
10 & \{a,b,c,e,i,p,l,h,o \} & \{d,f,g,j,k,m,n\} & 11 \\
\hline
11 & \{a,b,c,e,i,p,l,h,o,n \} & \{d,f,g,j,k,m\} & 12 \\
\hline
\end{tabular}
\end{figure}

L'algorithme s'arrête et renvoi donc cette coupe. Cependant on remarque que si l'on prend la coupe $(S,V-S)$ avec $S= \{a,c,f,h,i,k,n,p\}$, on obtient une coupe de taille 24.
\end{enumerate}

\subsection{Constructions de PTAS}

\subsubsection*{Exercice 4 - Sur le problème de Partition}

\begin{enumerate}
\item Si $r=2$, on considère la solution $(A,\emptyset)$. Comme on
  cherche une partition entre deux ensembles, cette solution est la
  pire des solutions. Mais, comme le poids de $A$ est au pire deux
  fois le poids $Y_1$ dans la solution optimale $(Y_1,Y_2)$ ( de même
  pour $\emptyset$ et $Y_2$), on a bien une $2$-approx. 

  Si $r>2$, comme on a une $2$-approx, en particulier on a une
  $r$-approx.
\item 
  \begin{enumerate}
  \item on cherche à montrer $\omega(Y_1)-L\le \frac{p(a_h)}{2}$. Par
    l'absurde, supposons que :
    \begin{eqnarray*}
      \omega(Y_1)-L> \frac{p(a_h)}{2} \implies 2\omega(Y_1)-\omega(A)<p(a_h)
    \end{eqnarray*}
    Donc, après avoir ajouter $a_h$ dans $Y_1$, on peut ajouter un
    autre objet de mÍme poids que $a_h$ or comme $p(a_{h+1})\le
    p(a_h)$, on peut ajouter alors $a_{h+1}$ dans $Y_1$. Contradiction
    car on a supposé que $a_h$ est le dernier objet ajouté dans $Y_1$
    (les objets sont triés).
  \item Supposons que $a_h$ a été ajouté lors de la première phase,
    alors par définition, tout les $a_j$ avec $j\in[\![ k(r)+1,n]\!]$
    ont été insérés dans $Y_2$. Donc, à chaque tour de boucle, on a
    l'invariant :
    \begin{equation*}
      \sum_{a_i\in Y_1} p(a_i) > \sum_{a_i\in Y_2} p(a_i)
    \end{equation*}
    De plus on peut remarquer que pour que ce cas se produise, il faut
    que après avoir ajouté $a_h$ à la première phase, tout les $a_j$
    de la deuxième phase on un poids trop grand pour être dans
    $Y_1$. Par consequent, on optient :
    \begin{equation*}
      L-\omega(Y_1) < a_n
    \end{equation*}
  \item Supposons que $a_h$ est ajoutÈ dans la deuxiËme phase. Par
    dÈfinition on a :
    \begin{equation*}
      \forall j\in[\![1,k(r)]\!], p(a_h)<p(a_j)
    \end{equation*}
    En effet, car sinon on aurait ajoutÈ $a_h$ dans la première
    phase. Pour montrer que $2L\ge p(a_h)(k(r)+1)$, on va raisonner
    par contradition :
    \begin{equation*}
      2L< p(a_h)(k(r)+1) \implies \omega(A) < p(a_h)(k(r)+1)
    \end{equation*}
    Or ce n'est pas possible car au pire des cas les $a_j$ avec $j\in
    [\![1,k(r)]\!]$ ont un poids supérieur à $a_h$ (car $h>k(r)$) et
    donc :
    \begin{equation*}
      p(a_h)(k(r)+1)<p(a_1)(k(r)+1)<\omega(A)
    \end{equation*} 
    On a donc une contradiction, et $2L\ge p(a_h)(k(r)+1)$.
  \item Si on a une solution optimale, alors nÈcessairement,
    $\omega(A)$ est un multiple de deux et on peut avoir $Y_1$ et
    $Y_2$ de même poids avec $Y_1\cup Y_2=A$. Donc on a :
    \begin{equation*}
      \omega(Y_1) = \omega(Y_2) = \frac{\omega(A)}{2} = L
    \end{equation*}
  \item On veut montrer que $\frac{\omega(Y_1)}{\omega{(Y_1^*)}}\le
    r$. Par l'absurde, on a :
    \begin{equation*}
      \frac{\omega(Y_1)}{\omega(Y^*_1)}>r \implies
      \frac{\omega(Y_1)}{L}>r \implies \omega(Y_1)>rL
    \end{equation*}
    Or on voit bien que c'est impossible. En effet si $r<2$ mais tend
    vers $2$, on voit que $\omega(Y_1)$ tend vers $\omega(A)$. Or par
    construction de l'algorithme c'est impossible. En effet, quand
    $Y_1$ est grand, l'algorithme met les futurs éléments dans
    $Y_2$. Donc  $\frac{\omega(Y_1)}{\omega{(Y_1^*)}}\le r$.
  \end{enumerate}
  \item On a :
    \begin{itemize}
    \item le tri se fait en $O(nlog(n))$
    \item la première phase 
    \item la deuxième phase peut se faire en $O(n)$. en effet, on peut
      utiliser deux variables temporaires pour stocker les sommes
      partielles, il ne reste plus que parcourir les $j\in
      [\![k(r)+1,n]\!]$.
    \end{itemize}
\end{enumerate}
\subsubsection*{Exercice 5 - Sur le problème du sac à  dos simple}

Soit $w_{1}, \dots, w_{n}$ les poids de $n$ objets, $b$ la capacité du sac à dos. On cherche à trouver $T \subseteq \{1, \dots, n \}$ tel que $\sum_{i \in T } w_{i}$ soit maximum.

\begin{enumerate}
\item \begin{enumerate}[a)]
\item Trier les $w_{i}, i \in \{1, \dots, n\}$ peut se faire en $O(n log(n))$. On répète la boucle $n$ fois et les éléments à l'intérieur s'effectuent en $O(1)$. On peut donc conclure que l'algorithme s'effectue en $O(n log(n))$.

\item On peut distinguer deux cas :
\begin{itemize}
\item Si $\sum_{i=1}^{n} w_{i} \leq b $, alors on peut mettre tous les objets dans le sac à dos. Donc $T= \{1, \dots, n\}$ et le cas se résout trivialement.
\item Si par contre $\sum_{i=1}^{n} w_{i} > b $, on peut démontrer par l'absurde qu'il existe $j$ tel que $cost(T) + w_{j+1} > b$. Supposons qu'un tel élément n'existe pas, alors à chaque étape de la boucle, l'élément $i$ est ajouté à $T$. En particulier si $i=n$, on rajoute l'élément $n$ à $T$ puisque $cost(T) + w_{n} = \sum_{i=1}^{n} w_{i} \leq b$, ce qui est absurde. \\
\end{itemize}

Montrons maintenant que dans le deuxième cas, on a forcément $cost(T) \geq \frac{b}{2}$. Etudions les trois cas possibles: 
\begin{itemize}
\item On ne peut pas avoir $j=0$ puisque $b \geq w_{1}$.
\item Si $j=1$, alors on a $w_{1} + w_{2} > b$ or on sait que $w_{1} \geq w_{2}$ et donc $2w_{1} \geq w_{1} + w_{2} > b$, d'où $cost(T) = w_{1} \geq \frac{b}{2}.$
\item Si $j\geq 2$ , on a alors $T=\{1,\dots,j\}$ d'après la démonstration précédente. $cost(T)= \sum_{i \in T } w_{i}\leq b$ et $cost(T) + w_{j+1} > b$. Supposons par l'absurde que $cost(T) < \frac{b}{2}$ alors on aurait :

\begin{equation*}
	w_{j+1} + \frac{b}{2} > cost(T) + w_{j+1} > b
\end{equation*}
On conclut que $w_{j+1} > \frac{b}{2}$, et puisque $j \geq 2$ alors $cost(T) \geq w_{1} + w_{2} \geq 2 w_{j+1} > b$. C'est une contradiction.
\end{itemize}

\item Montrons que l'algorithme admet une performance relative de deux. Soit $I$ une instance quelconque du problème du sac à dos. Alors $Opt(I) \leq b$. Notre algorithme nous assure une solution $A(I) \geq \frac{b}{2}$ d'après la question précédente. On a alors :
\begin{equation*}
	\frac{A(I)}{Opt(I)} \geq \frac{b}{2} * \frac{1}{b} = \frac{1}{2} 
\end{equation*}
\end{enumerate}

\item \begin{enumerate}[a)]
\item Il y a $\binom {n}{k} = \frac{n!}{k! (n-k)!}$ ensembles $S$ de taille $k$. On peut donc calculer le nombre total d'ensembles S:
\begin{equation*}
	N=\sum_{i=1}^{k} \binom{n}{i} = n! ( \frac{1}{(n-1)!} + \dots + \frac{1}{k!(n-k)!}) = n + \frac{n(n-1)}{2!} + \dots + \frac{n(n-1)\dots(n-k+1)}{k!}
\end{equation*}
Il y 'en a donc N $\approx O(n^{k}). $ Mais puisque pour chacun de ces ensembles, on utilise un algorithme glouton en $O(nlog(n))$. On arrive à une complexité en $O(n^{k+1})$.

\item \begin{enumerate}[i.]
\item Si $p \leq k$, cela signifie que l'on va trouver la meilleure solution $S$ possible et donc que $Sol_{PTAS}(I) = Opt(I)$.

\item Supposons maintenant que $ p > k $. On note $P=\{i_{1},\dots, i_{k}\}$ 
les indices associés à l'ensemble S. $w_{i_{1}}, \dots , w_{i_{k}}$ sont les points associés. Et on note $P^*$ les indices des objets de l'ensemble retourné par notre algorithme $S^*$.

\begin{enumerate}[A.]
\item Si $P^* = M$ alors on a $Sol_{PTAS}(I) = Opt(I)$.
\item Supposons maintenant que $P^* \neq M$. On sait déjà que $b \geq cost(M)$. Soit $S$ un ensemble de taille $k$ composé des $k$ objets dont les poids sont maximaux et appliquons notre algorithme glouton qui va ajouter des objets. D'après la question 1.a), il existe $i_{q}$ tel que $cost(P^{*}) + w_{i_{q}} > b$ (sinon on ajouterais tout les objets). Soit j le premier objet ajouté par l'algorithme glouton, alors $j> i_{k}$ sinon on aurait pris cet objet à la place. On a donc $i_{k} < j < i_{q}$. Si on ajoute pas d'objets, on a quand même $i_{k} < i_{q}$, c'est à dire $w_{i_{q}} < w_{i_{k}}$ car sinon $cost(S) > b$.

\item On a $w_{i_{q}} < w_{i_{k}}$ donc $(k+1)w_{i_{q}} < kw_{i_{k}} + w_{i_{k}} \leq  cost(P^{*})+ w_{i_{q}} \leq cost(M)$ et donc on peut déduire que $w_{i_{q}} \leq \frac{cost(M)}{k+1}$

\item $cost(P^{*}) + w_{i_{q}} \geq cost(M)$ d'après la question B. On peut donc écrire que :
\begin{equation*}
	\frac{cost(M)}{k+1} \geq w_{i_{q}} \geq cost(M) - cost(P^{*})
\end{equation*}
\begin{equation*}
	\frac{cost(M)}{cost(P^{*})} \geq (k+1) \frac{cost(M)}{cost(P^{*})} - (k+1)
\end{equation*}
\begin{equation*}
	\frac{cost(M)}{cost(P^{*})} \leq \frac{k+1}{k} = 1 + \frac{1}{k} = 1 + \epsilon
\end{equation*}
Il s'agit donc bien d'un algorithme PTAS.
\end{enumerate}
\end{enumerate}
\end{enumerate}
\end{enumerate}

\subsection{Construction d'un FPTAS : le problème de la somme d'un sous-ensemble}
\subsubsection{Un algorithme de complexité exponentielle}

\begin{enumerate}
\item Si les deux liste $L$ et $L'$ sont triés alors la procédure $FUSIONNER-LISTES(L,L')$ s'effectue en $O(n)$ où $n= max( taille(L), taille(L'))$. En effet, il suffit de parcourir les deux listes en prenant à chaque fois le plus petit élément.

\item La trace de l'algorithme pour $S= \{1,4,5\} $ et $n=3$ est effectué dans le tableau suivant :

\begin{figure}[H]
\center
\begin{tabular}{|c|c|c|c|}
\hline
\text{i} & $L_{i-1}$ &  $x_{i}$ &$L_{i}$  \\
\hline
1 & \{0\} & 1 & \{0,1\} \\
\hline
2 & \{0,1\}& 4 & \{0, 1 , 4 , 5 \}\\
\hline
3 & \{0, 1 , 4 , 5 \} & 5 & \{0,1,4,5,6,9,10\}\\
\hline
\end{tabular}
\end{figure}
L'algorithme retourne 10.

\item On note $P_{i}$ l'ensemble des valeurs pouvant être obtenues en faisant la somme de tous les éléments d'un sous ensemble de $\{x_{1},\dots , x_{i} \}$. Il est évident de voir que $P_{i} = P_{i-1} \cup (P_{i-1} + x_{i})$.
En effet si l'on note $S_{i}$ l'ensemble des éléments de $P_{i}$ utilisant l'élément $x_{i}$ et $S'_{i}$ les éléments de $P_{i}$ n'utilisant pas $x_{i}$ alors on a $P_{i} = S_{i} \cup S'_{i}$. Et on remarque facilement que $S_{i} = P_{i-1} + x_{i}$ et que $S'_{i} = P_{i-1}$. \\
Montrons par récurrence sur $i$ que la liste $L_{i}$ est une liste tirée contenant tous les éléments de $P_{i}$ dont la valeur n'est pas supérieure à t.
\begin{itemize}
\item Pour $i=0$, il n'y a qu'un élément dans $L_{0}$, donc cette liste est triée.
\item Supposons que $L_{i\in \{1,\dots,n-1\} }$ soit triée, montrons que la liste $L_{i+1}$ reste triée. Il est évident que $L_{i} + x_{i+1}$ est triée, on peut donc appeler la procédure $FUSIONNER-LISTES(L_{i},L_{i}+x_{i+1})$ qui nous rend une liste triée. On supprime ensuite tout les éléments supérieurs à $t$, ce qui nous garantie que la liste $L_{i+1}$ est triée et ne contient pas d'éléments supérieurs à t. \\
\end{itemize}
La longueur maximale de la liste $L_{i}$ est $2^{i}$. En effet, dans le pire des cas, $L_{i-1} \cap (L_{i-1} + x_{i}) = \emptyset$ pour tout $i\in \{1,\dots, n\}$, et donc la taille de $L_{i}$ est doublée à chaque itération. \\
On peut donc conclure sur la complexité exponentielle de l'algorithme, en effet, pour fusionner l'ensemble des listes on a une complexité en $\sum_{1}^{n} i*2^{i} \approx n* 2^{n+1} $  et donc $O(2^{n}).$
\end{enumerate}

\subsubsection{Un schéma d'approximation en temps entièrement polynomial}

\begin{enumerate}
\item Le déroulement des calculs est présenté dans le tableau suivant :

\begin{figure}[H]
\center
\begin{tabular}{|c|c|c|}
\hline

$y_{i}$ & Existe t'il $z$ tel que $\frac{y-z}{y} \leq \delta$ & L' \\
\hline
10 & non & [ 10 ] \\
\hline
11 & oui & [ 10 ] \\
\hline
12 & non & [ 10 , 12] \\
\hline
15 & non & [ 10 , 12, 15] \\
\hline
20 & non & [ 10 , 12, 15, 20] \\
\hline
21 & oui & [ 10 , 12, 15, 20] \\
\hline
22 & oui & [ 10 , 12, 15, 20] \\
\hline
23 & non & [ 10 , 12, 15, 20, 23] \\
\hline
24 & oui & [ 10 , 12, 15, 20, 23] \\
\hline
29 & non & [ 10 , 12, 15, 20, 23, 29] \\
\hline
\end{tabular}
\end{figure}
L'algorithme renvoie $L' = [10, 12, 15, 20, 23, 29 ]$.

\item Question ?

\item On applique l'algorithme sur une liste $L=[ 104, 102, 201, 101 ]$ avec $t=308$ et $\epsilon = 0.2$. La trace de l'algorithme est donné dans le tableau suivant :
 
 \begin{figure}[H]
\center
\begin{tabular}{|c|c|c|c|}
\hline

$L_{i-1}$& $x_{i}$ & $L_{i}$ & $L_{i}$ après SEUILLER($L_{i}, 0.05$)\\
\hline
[ 0 ] & 104 & [ 0 , 104 ] & [ 0 , 104 ] \\
\hline
[ 0 , 104 ] & 102 & [ 0 , 102 , 104 , 206] & [0 , 102, 206]\\
\hline
[0 , 102, 206] & 201 & [0 , 102, 201, 206, 303, 407] & [0, 102, 201, 303] \\
\hline
[0, 102, 201, 303]  & 101 & [0, 101, 102, 201, 203, 302, 303, 404 ] & [0, 101, 201, 302] \\
\hline
\end{tabular}
\end{figure}
L'algorithme rend 302.

\item Soit $C^*$ la valeur d'une solution optimale et $C$ la valeur de la solution donnée par notre algorithme.
\begin{enumerate}[a)]
\item Montrons par récurrence sur $i$ que $\forall y \in P_{i}, y\leq t, \exists z \in L_{i}$ tel que  $(1 - \frac{\epsilon}{n})^{i}y^{*} \leq z \leq y^{*}$.
\begin{itemize}
\item Pour $i=1$, $\forall y \exists z$ tel que $(1- \delta)y \leq z \leq y$ par définition du seuillage.
\item Supposons que $\forall y \exists z, ( 1 - \frac{\epsilon}{n})^{i} y \leq z \leq y $. Alors soit :
	\begin{itemize}
	\item $y \in P_{i}$. Si le $z$ précédent à été supprimé, alors $\exists z', (1 - \frac{\epsilon}{n})z \leq z' \leq z $. Donc $(1 - \frac{\epsilon}{n})^{i+1}y \leq z ( 1 - \frac{\epsilon}{n}) \leq z' \leq z \leq y$ sinon $(1 - \frac{\epsilon}{n})^{i+1}y \leq (1 - \frac{\epsilon}{n})^{i}y = z \leq y. $Cela reste vrai.
	\item $y \notin P_{i}$. $y=y' + x_{i+1}$ avec $y' \in P_{i}$ et  $\exists z', (1 - \frac{\epsilon}{n})^{i}y' \leq z' \leq y'$.
	\begin{itemize}
	\item Si $z' + x_{i+1} \in P_{i+1},$ 
	\begin{equation*}
		(1 - \frac{\epsilon}{n})^{i} y' + x_{i+1} \leq z' + x_{i+1} \leq y' + x_{i+1}
	\end{equation*}
	\begin{equation*}
		(1- \frac{\epsilon}{n})^{i} (y' + x_{i+1}) \leq (1 - \frac{\epsilon}{n})^{i}y' + x_{i+1} \leq z' + x_{i+1}
	\end{equation*}
	\begin{equation*}
		(1-\frac{\epsilon}{n})^{i+1} \leq (1- \frac{\epsilon}{n})^{i} y \leq z \leq y
	\end{equation*}
	\item Sinon :
	\begin{equation*}
		\exists z, (1 - \frac{\epsilon}{n})(z' + x_{i+1}) \leq z \leq z' + x_{i+1}
	\end{equation*}
	\begin{equation*}
		(1 - \frac{\epsilon}{n})^{i}y' + x_{i+1} \leq z' + x_{i+1} \leq y' + x_{i+1}
	\end{equation*}
	\begin{equation*}
		(1 - \frac{\epsilon}{n})^{i+1} (y' + x_{i+1}) \leq (1- \frac{\epsilon}{n})^{i+1}y' + (1 - \frac{\epsilon}{n}) x_{i+1} \leq (1- \frac{\epsilon}{n})z' + x_{i+1} \leq z \leq z' + x_{i+1} \leq y' + x_{i+1}
	\end{equation*}
	\begin{equation*}
		(1 - \frac{\epsilon}{n})^{i+1} y \leq z \leq y	
	\end{equation*}
	En particulier, $(1 - \frac{\epsilon}{n})^{n}y^{*} \leq z \leq y^{*}$ donc $1 \geq \frac{z}{y*} \geq (1 - \frac{\epsilon}{n})^{n}$
	\end{itemize}	
	\end{itemize}
\end{itemize}
\end{enumerate}

\item \begin{enumerate}[a)]
\item Si on a $\frac{z}{z'} \leq \frac{1}{1- \frac{\epsilon}{n}},$ alors $z(1 - \frac{\epsilon}{n}) \leq z ,$ on aurait donc supprimé $z$.
\item Supposons que le $1^{er}$ élément est 1 et le dernier élément $t$. 
\begin{equation*}
	\frac{z_{1}}{z_{2}} * \frac{z_{2}}{z_{3}}* \dots* \frac{z_{n-1}}{z_{n}} = t	
\end{equation*}
\begin{equation*}
	nlog(\frac{1}{1 - \frac{\epsilon}{n}}) \leq log( \frac{z_{1}}{z_{2}}) + \dots + log(\frac{z_{n-1}}{z_{n}}) = log(t)	
\end{equation*}
\begin{equation*}
	n\leq \frac{ log(t) }{ - log(1 - \frac{\epsilon}{n})} \text{ donc } n \leq \frac{ln(t)}{- ln(1 - \frac{\epsilon}{n})}
\end{equation*}
\end{enumerate}

\end{enumerate}

\subsubsection*{Exercice 6 - Programmation dynamique}

\subsubsection*{Exercice 7 - Sur le produit matriciel}

\subsubsection*{Exercice 8 - Résolution numérique}

\subsubsection*{Exercice 9 - Seuil d'approximation pour le problème Bin Packing}

\subsubsection*{Exercice 10 - Seuil d'approximation pour le problème de la coloration de sommets (reps. d'arêtes)}

\newpage
\subsubsection*{Exercice 11 - Comparaisons branch and bound and branch and cut}

\begin{enumerate}
\item On peut tracer les droites correspondantes aux contraintes de $PL_{0}$ :
\begin{itemize}
\item {$y_{1}=5-\frac{3}{2}x$}
\item {$y_{2}=\frac{17}{2}-\frac{2}{5}x$}
\end{itemize}

\begin{figure}[h]
\centering
\begin{tikzpicture}[>=stealth]
    \begin{axis}[
        xmin=0,xmax=10,
        ymin=0,ymax=6,
        axis x line=middle,
        axis y line=middle,
        axis line style=->,
        xlabel={$x$},
        ylabel={$y$},
        ]
        \addplot[no marks,black,-] expression[domain=0:10/3,samples=100]{5-(3/2)*x} 
                    node[pos=0.65,anchor=south west]{$y_{1}=5-\frac{3}{2}x$}; 
        \addplot[no marks,black,-] expression[domain=0:17/2,samples=100]{17/5-(2/5)*x} 
                    node[pos=0.65,anchor=south west]{$y_{2}=\frac{17}{5}-\frac{2}{5}x$}; 
    \end{axis}
\end{tikzpicture}
   \caption{Représentation des équations de $PL_{0}$.}
\end{figure}

Le polytope associé aux équations de $PL_{0}$ est donc celui formé par les points : $P_{0}(0,0)$, $P_{1}(0,\frac{17}{5})$, $P_{2}(\frac{16}{11}, \frac{31}{11})$ et $P_{3}(\frac{10}{3},0)$

\item On peut tracer la fonction objective :
\begin{itemize}
\item $y=-2x+k, k \in \mathbf{R}$ (rouge)
\end{itemize}

\begin{tikzpicture}[>=stealth]
    \begin{axis}[
        xmin=0,xmax=10,
        ymin=0,ymax=6,
        axis x line=middle,
        axis y line=middle,
        axis line style=->,
        xlabel={$x$},
        ylabel={$y$},
        ]
        \addplot[no marks,black,-] expression[domain=0:10/3,samples=100]{5-(3/2)*x} 
                    node[pos=0.65,anchor=south west]{$y_{1}=5-\frac{3}{2}x$}; 
        \addplot[no marks,blue,-] expression[domain=0:17/2,samples=100]{17/5-(2/5)*x} 
                    node[pos=0.65,anchor=south west]{$y_{2}=\frac{17}{5}-\frac{2}{5}x$}; 
                    
	 \addplot[no marks,red,-] expression[domain=0:17/2,samples=100]{-2*x+20/3} 
                    node[pos=0.65,anchor=south west]{Fonction objective}; 
    \end{axis}
\end{tikzpicture}

La solution optimale pour $PL_{0}$ est donc $x_{1}=\frac{10}{3}$ et $x_{2}={0}$ avec $z=\frac{20}{3}$.

\item On commence par reprendre le programme linéaire donné :
\begin{displaymath}
PL_{0}\begin{cases} 
\text{max } z(x_{1},x_{2})=2x_{1}+x_{2} \\
2x_{1}+5x_{2} \leq 17 \\
3x_{1}+2x_{2} \leq 10 \\
x_{1}, x_{2} \geq 0
\end{cases}
\end{displaymath}
On ajoute les variables d'écarts $x_{3}$ et $x_{4}$ pour obtenir $PL_{1}$ :

\begin{displaymath}
PL_{1}\begin{cases} 
\text{max } z(x_{1},x_{2})=2x_{1}+x_{2} \\
2x_{1}+5x_{2} + x_{3} = 17 \\
3x_{1}+2x_{2} + x_{4} = 10 \\
x_{1}, x_{2} \geq 0
\end{cases}
\end{displaymath}

On obtient donc le tableau initial : \\
\begin{tabular}{|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|}
   \hline
  \multicolumn{3}{|c|}{} & 2 & 1 & 0 & 0\\
     \hline
   & && $x_{1}$&$x_{2}$ &$x_{3}$ &$x_{4}$\\
   \hline
   0&$x_{3}$ &17& 2&5 &1 &0\\
   \hline
   0&$x_{4}$ & 10 &3 & 2&0 &1\\
   \hline
      & $z$& 0&-2 &-1 &0 &0\\
      \hline
\end{tabular}

La variable entrante est $x_{1}$ et la variable sortante est $x_{4}$. 
Le tableau final est donc : \\
\begin{tabular}{|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|}
   \hline
  \multicolumn{3}{|c|}{} & 2 & 1 & 0 & 0\\
   \hline
   & && $x_{1}$&$x_{2}$ &$x_{3}$ &$x_{4}$\\
   \hline
   0&$x_{3}$ &$\frac{31}{3}$& 0&$\frac{11}{3} $&1 &$\frac{-2}{3}$\\
   \hline
   2&$x_{1}$ & $\frac{10}{3}$ &1 & $\frac{2}{3}$&0 & $\frac{1}{3}$\\
   \hline
      & $z$& $\frac{20}{3}$&0 &$\frac{1}{3}$ &0 &$\frac{2}{3}$\\
      \hline
\end{tabular}

La solution optimale est donc $x_{1}=\frac{10}{3}$ et $x_{2}={0}$ avec $z=\frac{20}{3}$.

\item

\begin{enumerate}[a)]
\item

On effectue notre Branch and Bound dans l'ordre : $x_{1}$ puis $x_{2}$. Puisque dans la solution optimale du $(PL)$, $x_{1} = \frac{20}{3}$, on a $x_{1} \leq 3$ ou que $x_{1} \geq 4 $. 
\begin{itemize}
\item Si l'on considère que $x_{1} \leq 3$, la solution optimale devient $z=\frac{13}{2}$ avec $x_{1}=3$ et $x_{2} = \frac{1}{2}$. On a ensuite, $x_{2} = 0$ ou $x_{2} > 0$. \\
\begin{itemize}
\item Si l'on considère que $x_{2}=0$, alors la solution optimale devient $z=6$ avec $x_{1}=3$ et $x_{2}=0$.
\item Si l'on considère que $x_{2} \geq 1$, alors la solution optimale devient $z= \frac{19}{3} \approx 6.33$ avec $x_{1} = \frac{8}{3}$ et $x_{2} = 1$. On ne développe pas plus cette branche puisque l'on à déjà trouvé une solution avec $z=6$.
\end{itemize}
\item Si l'on considère que $x_{1} \geq 4$, la deuxième contrainte est violée.
\end{itemize}
L'arbre du Branch and bound récapitulatif est donné plus bas.

\tikzset{
  head/.style = {fill = orange!90!blue,
                 label = center:\textsf{\Large H}},
  tail/.style = {fill = blue!70!yellow, text = black,
                 label = center:\textsf{\Large T}}
}
\begin{tikzpicture}[
    scale = 1.5, transform shape, thick,
    every node/.style = {draw, circle, minimum size = 10mm},
    grow = down,  % alignment of characters
    level 1/.style = {sibling distance=3cm},
    level 2/.style = {sibling distance=4cm}, 
    level 3/.style = {sibling distance=2cm}, 
    level distance = 1.25cm
  ]
  \node[fill = gray!40, shape = rectangle, rounded corners,
    minimum width = 6cm, font = \sffamily] { Valeur de $S_{LP}$} 
  child { node[{fill = orange,
                 label = center:\textsf{ $\frac{20}{3} $}}] (Start){}
   child {   node [{fill = orange,
                 label = center:\textsf{ $6.5_{1}$}}] (A) {}
     child { node [{fill = orange,
                 label = center:\textsf{ $6_{2}$}}] (B) {}}
     child { node [{fill = orange,
                 label = center:\textsf{ $(\frac{19}{3})_{3}$}}] (C) {}}
   }
   child {   node [{fill = orange,
                 label = center:\textsf{ $\emptyset_{4}$}}] (D) {}}
  };

  % Labels des arêtes
  \begin{scope}[nodes = {draw = none}]
    \path (Start) -- (A) node [near start, left]  {$x_{1} \leq 3$};
    \path (A)     -- (B) node [near start, left]  {$x_{2} =0 $};
    \path (A)     -- (C) node [near start, right] {$x_{2} \geq 1$};
    \path (Start) -- (D) node [near start, right] {$x_{1} \geq 4$};
    \begin{scope}[nodes = {below = 11pt}]
      \node            at (C) {Plus grand};
      \node            at (D) {Contrainte violée};
    \end{scope}
  \end{scope}
\end{tikzpicture}

\item
Puisque que l'on a $\frac{31}{3} = \frac{11}{3} x_{2} + x_{3} - \frac{2}{3} x_{4} $, on peut déduire que : $ \frac{11}{3} x_{2} - \frac{2}{3} x_{4} \geq \frac{1}{3} $. \\
Puisque l'on a $\frac{10}{3} = x_{1} + \frac{2}{3} x_{2} + \frac{1}{3}x_{4}$ , on peut donc déduire que $x_{4}=10 - 3x_{1} - 2x_{2}$. \\
On obtient finalement la contrainte : $2x_{1} + 5x_{2} \geq 7$. 

Le tableau final donne :

\begin{tabular}{|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|}
   \hline
  \multicolumn{3}{|c|}{} & 2 & 1 & 0 & 0 & 0\\
   \hline
   & 	&	& $x_{1}$	&	$x_{2}$ 	&$x_{3}$ &$x_{4}$ & $x_{5}$\\
   \hline
0&$x_{3}$& 10  &     0 &     0      &1      &0   &   1         \\
2&$x_{1}$& $\frac{36}{11}$ &  1 &     0   &   0 &     $\frac{5}{11}$&   $\frac{2}{11}$    \\    
1&$x_{2}$&  $\frac{1}{11} $ &  0    &  1     & 0     & $\frac{-2}{11} $ & $\frac{-3}{11}  $   \\  
&z&  $\frac{73}{11}$&  0    &  0    &  0     & $\frac{8}{11} $ & $\frac{1}{11}$   \\
      \hline
\end{tabular}

On choisi l'équation $\frac{36}{11} = x_{1} + \frac{5}{11} x_{4} + \frac{2}{11}x_{5}$, on déduit donc $\frac{5}{11} x_{4} + \frac{2}{11}x_{5} \geq \frac{3}{11}$. Ce qui revient à écrire par l'équation précédente que $\frac{36}{11} - x_{1} \geq \frac{3}{11}$ et donc que $x_{1} \leq 3$. 

\begin{tabular}{|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|p{0.75cm}|}
   \hline
  \multicolumn{3}{|c|}{} & 2 & 1 & 0 & 0 & 0 & 0\\
   \hline
   & 	&	& $x_{1}$	&	$x_{2}$ 	&$x_{3}$ &$x_{4}$ & $x_{5}$ & $x_{6}$\\
   \hline
0&$x_{3}$& $\frac{17}{2}$&     0 &     0      &1      &$\frac{-5}{2} $  &   0 & $\frac{11}{2}   $      \\
0&$x_{4}$& $\frac{3}{2}$ &  0 &     0   &   0 &     $\frac{5}{2}$& 1 &  $\frac{-11}{2}$    \\    
1&$x_{2}$&  $\frac{1}{2} $ &  0    &  1     & 0     & $\frac{1}{2} $ & 0 & $\frac{-3}{2} $  \\  
2&$x_{1}$&  3                &  1    &  0    & 0     & 0 & 0& 1   \\  
&z&  $\frac{13}{2}$           &  0    &  0    &  0     & $\frac{1}{2} $& 0 & $\frac{1}{2}$   \\
      \hline
\end{tabular}

On sélectionne l'équation $\frac{1}{2} = x_{2} + \frac{1}{2} x_{4} - \frac{3}{2} x_{6}$. Donc on déduit que $\frac{1}{2} \leq \frac{-3}{2}x_{6}$
\end{enumerate}
\end{enumerate}

\section{Partie Pratique}

\subsection{Programmation dynamique}

\subsection{Branch and Bound}

\subsection{Comparaisons entre un algorithme de complexité exponentielle et un FP-TAS}

\end{document}
